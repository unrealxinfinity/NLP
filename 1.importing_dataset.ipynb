{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing First Assignment\n",
    "#### This is the notebook for the first assignment about the dataset **\"Polite Guard\"**. The objective of this work is to come up with a pipeline that builds a robust and good model for text classification\n",
    "#### The following dependencies are needed:\n",
    "`\n",
    "pip install datasets pandas nltk scikit-learn wordcloud matplotlib gensim\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing the dataset**\n",
    "##### The first step is to import the dataset we are using, directly from the library provided by Hugging Face. The original dataset already split test and training data, as well as validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'source', 'reasoning'],\n",
      "        num_rows: 80000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label', 'source', 'reasoning'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'source', 'reasoning'],\n",
      "        num_rows: 10200\n",
      "    })\n",
      "})\n",
      "{'text': \"Your flight has been rescheduled for 10:00 AM tomorrow. Please check the airport's website for any updates or changes.\", 'label': 'neutral', 'source': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'reasoning': 'This text would be classified as \"neutral\" because it provides factual information about the flight reschedule without any emotional undertones or attempts at politeness. The tone is impersonal and focused solely on conveying the necessary details.'}\n",
      "{'text': 'I appreciate your interest in our vegetarian options. I can provide you with a list of our current dishes that cater to your dietary preferences.', 'label': 'somewhat polite', 'source': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'reasoning': \"This text is somewhat polite because it acknowledges the customer's interest and shows a basic level of respect by offering assistance. The tone is direct and lacks additional warmth or formality, but it communicates a willingness to help by providing the requested information.\"}\n",
      "{'text': \"Are you seriously complaining about the tour not being exactly as described? It's not like we're running a five-star hotel here, we're just a local guide service. Get over it.\", 'label': 'impolite', 'source': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'reasoning': 'This text is impolite because it uses a condescending tone and dismissive language, such as \"Get over it.\" The phrase \"not like we\\'re running a five-star hotel here\" is also belittling and unprofessional, showing a lack of consideration for the customer\\'s feelings.'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Intel/polite-guard\");\n",
    "print(dataset);\n",
    "\n",
    "training_set = dataset[\"train\"]\n",
    "test_set = dataset[\"test\"]\n",
    "validation_set = dataset[\"validation\"]\n",
    "\n",
    "\n",
    "for i in training_set:\n",
    "    print(i)  \n",
    "    break\n",
    "\n",
    "for i in test_set:\n",
    "    print(i)  \n",
    "    break\n",
    "\n",
    "for i in validation_set:\n",
    "    print(i)  \n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataset Initial Analysis**\n",
    "##### The text corpuses are mainly about different types of language in terms of formality, the label to be classified is if the corpus is a polite or impolite. **There are 4 classes which are \"impolite\" , \"neutral\" , \"somewhat polite\" and \"polite\"**\n",
    "##### There are four features of the dataset which are:\n",
    "- ##### **text** - actual text corpus;\n",
    "- ##### **label** - class label to identify text formality;\n",
    "- ##### **reasoning** - why it was labeled as that class;\n",
    "- ##### **source** - source of the text;\n",
    "##### The majority of the dataset were **result of prompting using different synthesis techniques**, including only 200 annotated real-life examples from corporate training.\n",
    "##### The prompting techniques used: \n",
    "- ##### 50,000 samples generated using Few-Shot prompting\n",
    "- ##### 50,000 samples generated using Chain-of-Thought (CoT) prompting\n",
    "- ##### 200 annotated samples from corporate trainings; \n",
    "##### The test/train/validation split was done as follows:\n",
    "- ##### **80k rows for training**;\n",
    "- ##### **20k rows for testing**;\n",
    "- ##### **remaining rows for validation (200 annotated samples)**;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
