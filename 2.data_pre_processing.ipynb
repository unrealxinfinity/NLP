{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the previous step in the pipeline: Importing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/magicojayz/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'source', 'reasoning'],\n",
      "        num_rows: 80000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label', 'source', 'reasoning'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'source', 'reasoning'],\n",
      "        num_rows: 10200\n",
      "    })\n",
      "})\n",
      "                                                text            label  \\\n",
      "0  Your flight has been rescheduled for 10:00 AM ...          neutral   \n",
      "1  We're happy to accommodate your dietary prefer...           polite   \n",
      "2  Our vegetarian options are available on the me...          neutral   \n",
      "3  I understand your frustration with the recent ...  somewhat polite   \n",
      "4  I'll do my best to find a suitable replacement...  somewhat polite   \n",
      "\n",
      "                                  source  \\\n",
      "0  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "1  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "2  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "3  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "4  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "\n",
      "                                           reasoning  \n",
      "0  This text would be classified as \"neutral\" bec...  \n",
      "1  This text is polite because it expresses grati...  \n",
      "2  This text would be classified as \"neutral\" bec...  \n",
      "3  This text would be classified as \"somewhat pol...  \n",
      "4  This text would be classified as \"somewhat pol...  \n",
      "                                                text            label  \\\n",
      "0  I appreciate your interest in our vegetarian o...  somewhat polite   \n",
      "1  I understand you're concerned about the ski le...  somewhat polite   \n",
      "2  Our technical skills course will cover the ess...          neutral   \n",
      "3  Our buffet hours are from 11 AM to 9 PM. Pleas...          neutral   \n",
      "4  I'll look into your policy details and see wha...  somewhat polite   \n",
      "\n",
      "                                  source  \\\n",
      "0  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "1  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "2  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "3  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "4  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "\n",
      "                                           reasoning  \n",
      "0  This text is somewhat polite because it acknow...  \n",
      "1  This text would be classified as \"somewhat pol...  \n",
      "2  This text would be classified as \"neutral\" bec...  \n",
      "3  This text would be classified as \"neutral\" bec...  \n",
      "4  This text would be classified as \"somewhat pol...  \n",
      "                                                text     label  \\\n",
      "0  Are you seriously complaining about the tour n...  impolite   \n",
      "1  Are you seriously complaining about the delay ...  impolite   \n",
      "2  We're happy to accommodate your dietary needs....    polite   \n",
      "3  I appreciate your question about our fees. We ...    polite   \n",
      "4  We appreciate your trust in our banking servic...    polite   \n",
      "\n",
      "                                  source  \\\n",
      "0  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "1  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "2  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "3  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "4  meta-llama/Meta-Llama-3.1-8B-Instruct   \n",
      "\n",
      "                                           reasoning  \n",
      "0  This text is impolite because it uses a condes...  \n",
      "1  This text is impolite because it uses a confro...  \n",
      "2  This text is polite because it shows a willing...  \n",
      "3  This text is polite because it shows appreciat...  \n",
      "4  This text is polite because it expresses grati...  \n"
     ]
    }
   ],
   "source": [
    "%run ./1.importing_dataset.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extracting text corpus**\n",
    "##### We have to extract the text from the documents in te dataset so we can use different representations to operate on.\n",
    "##### Note that this is an unclean version of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Your flight has been rescheduled for 10:00 AM tomorrow. Please check the airport's website for any updates or changes.\", \"We're happy to accommodate your dietary preferences. Our vegetarian options are carefully crafted to ensure a delicious and satisfying meal. Would you like me to recommend some dishes that fit your needs?\", 'Our vegetarian options are available on the menu, and our chef can modify any dish to suit your dietary needs.', \"I understand your frustration with the recent tournament results, and I'll review the standings to see what we can do to improve your experience.\", \"I'll do my best to find a suitable replacement for the item you're looking for, but I need to know more about what you're looking for.\"]\n",
      "['I appreciate your interest in our vegetarian options. I can provide you with a list of our current dishes that cater to your dietary preferences.', \"I understand you're concerned about the ski lessons, and I'll look into the options for rescheduling.\", 'Our technical skills course will cover the essential topics in data analysis, including data visualization and statistical modeling. The course materials will be available on our learning platform.', 'Our buffet hours are from 11 AM to 9 PM. Please note that we have a limited selection of options available during the lunch break.', \"I'll look into your policy details and see what options are available to you.\"]\n"
     ]
    }
   ],
   "source": [
    "unclean_corpus = []\n",
    "for i in range(0, len(training_set[\"text\"])):\n",
    "    unclean_corpus.append(training_set['text'][i]);\n",
    "print(unclean_corpus[0:5]);\n",
    "\n",
    "\n",
    "unclean_corpus_test = []\n",
    "for i in range(0, len(test_set[\"text\"])):\n",
    "    unclean_corpus_test.append(test_set['text'][i]);\n",
    "print(unclean_corpus_test[0:5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cleaning the text corpus**\n",
    "##### Now we need to process the unclean text corpus, by performing actions such as:\n",
    "- ##### Removing punctuation;\n",
    "- ##### Lower case folding;\n",
    "- ##### Stemming (using PorterStemmer);\n",
    "- ##### Removing Stop Words (optional);\n",
    "##### For that effect we will import [regular expression](https://docs.python.org/3/library/re.html) library and [nltk](https://www.nltk.org/api/nltk.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/magicojayz/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/magicojayz/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4') \n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/magicojayz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flight reschedule tomorrow please check airport web site update change', 'happy fit dietary taste vegetarian alternative carefully craft see delightful meet meal would like recommend serve meet require', 'vegetarian alternative available fare chef change serve case dietary require', 'see frustration recent tournament effect review stand see improve have', 'good find suited substitute item seem require know seem']\n",
      "['appreciate interest vegetarian alternative provide list current serve provide dietary taste', 'see concern ski lesson seem alternative reschedule', 'technical skill of course cross requirement matter data analysis include data visualization statistical pattern of course material available learn platform', 'buffet hour prime minister please note limited selection alternative available lunch disclose', 'seem policy detail see alternative available']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "synonym_cache = {}\n",
    "\n",
    "def freq_syn(word):\n",
    "    if word in synonym_cache:\n",
    "        return synonym_cache[word]\n",
    "    \n",
    "    synsets = wordnet.synsets(word)\n",
    "    if not synsets:\n",
    "        synonym_cache[word] = word \n",
    "        return word\n",
    "    \n",
    "    lemmas = []\n",
    "    for syn in synsets:\n",
    "        for lemma in syn.lemmas():\n",
    "            lemmas.append((lemma.name(), lemma.count()))\n",
    "\n",
    "    if not lemmas:\n",
    "        synonym_cache[word] = word\n",
    "        return word\n",
    "\n",
    "    sorted_lemmas = sorted(lemmas, key=lambda x: x[1], reverse=True)\n",
    "    most_freq = sorted_lemmas[0][0].replace('_', ' ').lower()\n",
    "    synonym_cache[word] = most_freq\n",
    "    return most_freq\n",
    "\n",
    "clean_corpus_syn = []\n",
    "\n",
    "for text in unclean_corpus:\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text).lower()\n",
    "    processed_words = []\n",
    "    for word in text.split():\n",
    "        if word not in stop_words:\n",
    "            synonym_word = freq_syn(word)\n",
    "            processed_words.append(synonym_word)\n",
    "\n",
    "    cleaned_text = ' '.join(processed_words)\n",
    "    clean_corpus_syn.append(cleaned_text)\n",
    "\n",
    "print(clean_corpus_syn[:5])\n",
    "\n",
    "\n",
    "clean_corpus_test_syn = []\n",
    "for text in unclean_corpus_test:\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text).lower()\n",
    "    processed_words = []\n",
    "    for word in text.split():\n",
    "        if word not in stop_words:\n",
    "            synonym_word = freq_syn(word)\n",
    "            processed_words.append(synonym_word)\n",
    "\n",
    "    cleaned_text = ' '.join(processed_words)\n",
    "    clean_corpus_test_syn.append(cleaned_text)\n",
    "print(clean_corpus_test_syn[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flight reschedul tomorrow pleas check airport websit updat chang', 'happi accommod dietari prefer vegetarian option care craft ensur delici satisfi meal would like recommend dish fit need', 'vegetarian option avail menu chef modifi dish suit dietari need', 'understand frustrat recent tournament result review stand see improv experi', 'best find suitabl replac item look need know look']\n",
      "['appreci interest vegetarian option provid list current dish cater dietari prefer', 'understand concern ski lesson look option reschedul', 'technic skill cours cover essenti topic data analysi includ data visual statist model cours materi avail learn platform', 'buffet hour pm pleas note limit select option avail lunch break', 'look polici detail see option avail']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer();\n",
    "sw = stopwords.words('english');\n",
    "clean_corpus = []\n",
    "for i in range(0,len(unclean_corpus)):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', unclean_corpus[i])\n",
    "    text = text.lower()\n",
    "    text = [ps.stem(word) for word in text.split() if not word in sw]\n",
    "    text = ' '.join(text)\n",
    "    clean_corpus.append(text)\n",
    "print(clean_corpus[0:5])\n",
    "\n",
    "clean_corpus_test = []\n",
    "for i in range(0,len(unclean_corpus_test)):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', unclean_corpus_test[i])\n",
    "    text = text.lower()\n",
    "    text = [ps.stem(word) for word in text.split() if not word in sw]\n",
    "    text = ' '.join(text)\n",
    "    clean_corpus_test.append(text)\n",
    "print(clean_corpus_test[0:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
